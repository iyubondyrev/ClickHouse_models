{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spider https://huggingface.co/datasets/spider\n",
    "import pandas as pd\n",
    "\n",
    "df_parquet = pd.read_parquet('/Users/ivanbondyrev/Downloads/train-00000-of-00001.parquet')\n",
    "df_parquet_test = pd.read_parquet('/Users/ivanbondyrev/Downloads/validation-00000-of-00001.parquet')\n",
    "\n",
    "with open('cleaned_data/Spider/spider_train.txt', \"w+\") as file:\n",
    "    for line in df_parquet['query']:\n",
    "        file.write(line + \"\\n\")\n",
    "\n",
    "with open('cleaned_data/Spider/spider_test.txt', \"w+\") as file:\n",
    "    for line in df_parquet_test['query']:\n",
    "        file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WikiSQL https://www.kaggle.com/datasets/shahrukhkhan/wikisql?resource=download&select=validation.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def write_to_file(name: str, df):\n",
    "    with open(f\"cleaned_data/WikiSQL/{name}.txt\", \"w+\") as file:\n",
    "        for line in df['sql']:\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "df_test = pd.read_csv('/Users/ivanbondyrev/Downloads/test.csv')\n",
    "df_validation = pd.read_csv('/Users/ivanbondyrev/Downloads/validation.csv')\n",
    "df_train = pd.read_csv('/Users/ivanbondyrev/Downloads/train.csv')\n",
    "\n",
    "write_to_file('train', df_train)\n",
    "write_to_file('test', df_test)\n",
    "write_to_file('validation', df_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clickhouse generated \n",
    "\n",
    "import re\n",
    "with open('/Users/ivanbondyrev/Downloads/query_log.tsv', 'r', encoding='latin-1') as file, open(\"dataset_tests_pr_60095.txt\", \"w\") as f:\n",
    "    for line in file:\n",
    "        if line.split(\"\\t\")[1] != \"QueryFinish\":\n",
    "            continue\n",
    "        string = line.split(\"\\t\")[16].encode().decode('unicode_escape')\n",
    "        string = re.sub(r'\\s+', ' ', string)\n",
    "        if string == \"SELECT 1\":\n",
    "            continue\n",
    "        if string.startswith(\"--\"):\n",
    "            continue\n",
    "        f.write(string)\n",
    "        f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KaggleDBQA https://github.com/Chia-Hsuan-Lee/KaggleDBQA\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open(\"cleaned_data/KaggleDBQA_combined.txt\", \"w+\") as combined_file:\n",
    "    for file_name_json in os.listdir(\"KaggleDBQA/examples\"):\n",
    "        if file_name_json[:-5].endswith(\"test\") or file_name_json[:-5].endswith(\"fewshot\"):\n",
    "            continue\n",
    "        with open(os.path.join(\"KaggleDBQA/examples\", file_name_json), 'r') as file_json, \\\n",
    "             open(\"cleaned_data/\" + file_name_json[:-5] + \".txt\", \"w+\") as file_txt:\n",
    "                data = json.load(file_json)\n",
    "                for elem in data:\n",
    "                    query: str = elem[\"query\"]\n",
    "                    file_txt.write(query + \"\\n\")\n",
    "                    combined_file.write(query + \"\\n\")\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
